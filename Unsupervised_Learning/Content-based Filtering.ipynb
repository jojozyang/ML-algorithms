{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd432bf-5125-4929-b316-75b413671fbf",
   "metadata": {},
   "source": [
    "# Content-based Filtering\n",
    "\n",
    "In this notebook, a content-based filtering will be implemented using a neural network to build a recommender system for movies.\n",
    "\n",
    "The code is adapted from Andrew Ng's 'Machine Learning Specialiation' course to accomplish the homework assignment. \n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Import Packages](#1)\n",
    "- [ 2 - Load the Data](#2)\n",
    "- [ 3 - Main Functions](#3)\n",
    "- [ 4 - Train the Network](#5)\n",
    "- [ 5 - Visualize the results](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb68fa-a7d6-4863-9a38-db78b0cd3e4a",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f96918-460d-4144-8a8e-6af3c2bd7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tabulate\n",
    "pd.set_option(\"display.precision\", 1)\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f64687-942a-42f0-b58b-c8d5167fbf12",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54420f1-e511-40c0-b16c-ba3c07870917",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train = genfromtxt('Content_data/content_item_train.csv', delimiter=',')\n",
    "user_train = genfromtxt('Content_data/content_user_train.csv', delimiter=',')\n",
    "y_train    = genfromtxt('Content_data/content_y_train.csv', delimiter=',')\n",
    "with open('Content_data/content_item_train_header.txt', newline='') as f:    #csv reader handles quoted strings better\n",
    "    item_features = list(csv.reader(f))[0]\n",
    "with open('Content_data/content_user_train_header.txt', newline='') as f:\n",
    "     user_features = list(csv.reader(f))[0]\n",
    "item_vecs = genfromtxt('Content_data/content_item_vecs.csv', delimiter=',')\n",
    "\n",
    "movie_dict = defaultdict(dict)\n",
    "count = 0\n",
    "#    with open('./data/movies.csv', newline='') as csvfile:\n",
    "with open('Content_data/content_movie_list.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for line in reader:\n",
    "        if count == 0:\n",
    "            count += 1  #skip header\n",
    "            #print(line) print\n",
    "        else:\n",
    "            count += 1\n",
    "            movie_id = int(line[0])\n",
    "            movie_dict[movie_id][\"title\"] = line[1]\n",
    "            movie_dict[movie_id][\"genres\"] = line[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "666a5738-86a2-408d-ba5e-859a6356dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb761b21-1e32-4411-91bb-8731a0c3b37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# scale training data\n",
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = user_train\n",
    "y_train_unscaled    = y_train\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(item_train)\n",
    "item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(user_train)\n",
    "user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(y_train.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(y_train.reshape(-1, 1))\n",
    "#ynorm_test = scalerTarget.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(np.allclose(item_train_unscaled, scalerItem.inverse_transform(item_train)))\n",
    "print(np.allclose(user_train_unscaled, scalerUser.inverse_transform(user_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dc35684-b79d-49bb-b994-45c8689724a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie/item training data shape: (40707, 17)\n",
      "movie/item test data shape: (10177, 17)\n"
     ]
    }
   ],
   "source": [
    "# To evaluate the results, split the data into training and test sets\n",
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {item_train.shape}\")\n",
    "print(f\"movie/item test data shape: {item_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4efa5-b583-494a-987e-6cc45183d2eb",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44390642-7464-4c14-a280-677f60c8e23a",
   "metadata": {},
   "source": [
    "## 3.1 - Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b694cc5c-8f2a-4af1-876a-a9b5bd4a6c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 16)]                 0         []                            \n",
      "                                                                                                  \n",
      " sequential (Sequential)     (None, 32)                   40864     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)   (None, 32)                   41376     ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOp  (None, 32)                   0         ['sequential[0][0]']          \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TF  (None, 32)                   0         ['sequential_1[0][0]']        \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 1)                    0         ['tf.math.l2_normalize[0][0]',\n",
      "                                                                     'tf.math.l2_normalize_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82240 (321.25 KB)\n",
      "Trainable params: 82240 (321.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# construct a neural network \n",
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([   \n",
    "    tf.keras.layers.Dense(units=256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([ \n",
    "    tf.keras.layers.Dense(units=256, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bb250e-8188-41dc-a867-9a5507a10ca1",
   "metadata": {},
   "source": [
    "## 3.2 Helper Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67bdcd31-2d59-4e4c-9cd9-e7bccd7b3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_vecs(user_vec, num_items):\n",
    "    \"\"\" given a user vector return:\n",
    "        user predict maxtrix to match the size of item_vecs \"\"\"\n",
    "    user_vecs = np.tile(user_vec, (num_items, 1))\n",
    "    return user_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85941c29-7ba9-4e8b-ad32-5d5710feb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_movies(y_p, item, movie_dict, maxcount=10):\n",
    "    \"\"\" print results of prediction of a new user. inputs are expected to be in\n",
    "        sorted order, unscaled. \"\"\"\n",
    "    count = 0\n",
    "    disp = [[\"y_p\", \"movie id\", \"rating ave\", \"title\", \"genres\"]]\n",
    "\n",
    "    for i in range(0, y_p.shape[0]):\n",
    "        if count == maxcount:\n",
    "            break\n",
    "        count += 1\n",
    "        movie_id = item[i, 0].astype(int)\n",
    "        disp.append([np.around(y_p[i, 0], 1), item[i, 0].astype(int), np.around(item[i, 2].astype(float), 1),\n",
    "                     movie_dict[movie_id]['title'], movie_dict[movie_id]['genres']])\n",
    "\n",
    "    table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2d1a9-0cc9-45f9-9524-fa750db9771d",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ad6b49a-ec37-4ba4-813d-a4af41da8857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1273/1273 [==============================] - 3s 1ms/step - loss: 0.1235\n",
      "Epoch 2/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1139\n",
      "Epoch 3/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1089\n",
      "Epoch 4/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1048\n",
      "Epoch 5/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.1023\n",
      "Epoch 6/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0994\n",
      "Epoch 7/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0971\n",
      "Epoch 8/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0949\n",
      "Epoch 9/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0932\n",
      "Epoch 10/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0917\n",
      "Epoch 11/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0902\n",
      "Epoch 12/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0884\n",
      "Epoch 13/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0873\n",
      "Epoch 14/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0861\n",
      "Epoch 15/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0848\n",
      "Epoch 16/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0835\n",
      "Epoch 17/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0823\n",
      "Epoch 18/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0810\n",
      "Epoch 19/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0802\n",
      "Epoch 20/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0792\n",
      "Epoch 21/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0783\n",
      "Epoch 22/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0777\n",
      "Epoch 23/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0768\n",
      "Epoch 24/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0761\n",
      "Epoch 25/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0752\n",
      "Epoch 26/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0748\n",
      "Epoch 27/30\n",
      "1273/1273 [==============================] - 2s 2ms/step - loss: 0.0741\n",
      "Epoch 28/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0734\n",
      "Epoch 29/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0729\n",
      "Epoch 30/30\n",
      "1273/1273 [==============================] - 2s 1ms/step - loss: 0.0724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x166129e90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use a mean squared error loss and an Adam optimizer.\n",
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "model.fit([user_train[:, u_s:], item_train[:, i_s:]], y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a70f7fc6-0aa1-4ccf-9bcb-3ffcf603d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 0s 842us/step - loss: 0.0818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08178229629993439"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba5a22-e098-4590-ba43-f3745bc9872b",
   "metadata": {},
   "source": [
    "It is comparable to the training loss indicating the model has not substantially overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3070b3b-34e3-4894-8b4d-41a9959fe580",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a>\n",
    "## 5 - Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e4034-5776-4c6c-8aee-34209456795a",
   "metadata": {},
   "source": [
    "## 5.1 - Predictions for a new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "246c5754-4ee5-43f4-b9bd-1cecea3e49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99842a8c-998a-4862-b792-456f3e0afc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                              </th><th>genres                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  4.5</td><td style=\"text-align: right;\">     98809</td><td style=\"text-align: right;\">         3.8</td><td>Hobbit: An Unexpected Journey, The (2012)          </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">      8368</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Prisoner of Azkaban (2004)    </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">      5816</td><td style=\"text-align: right;\">         3.6</td><td>Harry Potter and the Chamber of Secrets (2002)     </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">    106489</td><td style=\"text-align: right;\">         3.6</td><td>Hobbit: The Desolation of Smaug, The (2013)        </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">     81834</td><td style=\"text-align: right;\">         4  </td><td>Harry Potter and the Deathly Hallows: Part 1 (2010)</td><td>Action|Adventure|Fantasy       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">    118696</td><td style=\"text-align: right;\">         3.4</td><td>The Hobbit: The Battle of the Five Armies (2014)   </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">     40815</td><td style=\"text-align: right;\">         3.8</td><td>Harry Potter and the Goblet of Fire (2005)         </td><td>Adventure|Fantasy|Thriller     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">     54001</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Order of the Phoenix (2007)   </td><td>Adventure|Drama|Fantasy        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">      5952</td><td style=\"text-align: right;\">         4  </td><td>Lord of the Rings: The Two Towers, The (2002)      </td><td>Adventure|Fantasy              </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">     57640</td><td style=\"text-align: right;\">         3.8</td><td>Hellboy II: The Golden Army (2008)                 </td><td>Action|Adventure|Fantasy|Sci-Fi</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th style=\"text-align: right;\">  y_p</th><th style=\"text-align: right;\">  movie id</th><th style=\"text-align: right;\">  rating ave</th><th>title                                              </th><th>genres                         </th></tr>\\n</thead>\\n<tbody>\\n<tr><td style=\"text-align: right;\">  4.5</td><td style=\"text-align: right;\">     98809</td><td style=\"text-align: right;\">         3.8</td><td>Hobbit: An Unexpected Journey, The (2012)          </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">      8368</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Prisoner of Azkaban (2004)    </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">      5816</td><td style=\"text-align: right;\">         3.6</td><td>Harry Potter and the Chamber of Secrets (2002)     </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">    106489</td><td style=\"text-align: right;\">         3.6</td><td>Hobbit: The Desolation of Smaug, The (2013)        </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">     81834</td><td style=\"text-align: right;\">         4  </td><td>Harry Potter and the Deathly Hallows: Part 1 (2010)</td><td>Action|Adventure|Fantasy       </td></tr>\\n<tr><td style=\"text-align: right;\">  4.4</td><td style=\"text-align: right;\">    118696</td><td style=\"text-align: right;\">         3.4</td><td>The Hobbit: The Battle of the Five Armies (2014)   </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">     40815</td><td style=\"text-align: right;\">         3.8</td><td>Harry Potter and the Goblet of Fire (2005)         </td><td>Adventure|Fantasy|Thriller     </td></tr>\\n<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">     54001</td><td style=\"text-align: right;\">         3.9</td><td>Harry Potter and the Order of the Phoenix (2007)   </td><td>Adventure|Drama|Fantasy        </td></tr>\\n<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">      5952</td><td style=\"text-align: right;\">         4  </td><td>Lord of the Rings: The Two Towers, The (2002)      </td><td>Adventure|Fantasy              </td></tr>\\n<tr><td style=\"text-align: right;\">  4.3</td><td style=\"text-align: right;\">     57640</td><td style=\"text-align: right;\">         3.8</td><td>Hellboy II: The Golden Army (2008)                 </td><td>Action|Adventure|Fantasy|Sci-Fi</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "print_pred_movies(sorted_ypu, sorted_items, movie_dict, maxcount = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e842276-ace2-4c07-ac9a-ad2035bf430e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
